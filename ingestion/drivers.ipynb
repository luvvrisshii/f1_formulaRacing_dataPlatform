{"cells":[{"cell_type":"markdown","source":["#### Ingestion"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ed17b909-6c64-4523-8ce4-b6c53bfdd476","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["#configurations"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1e77b947-11ea-4d17-afce-0c2b3d174ba0","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%run \"../utils/configs/functions\""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e47bfe48-0398-4c3f-9d4a-64ffa8ad8f57","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%run \"../utils/configs/paths\""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9166769e-ebff-4131-9deb-835d440171d5","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.types import StructField, StructType, IntegerType, StringType, DoubleType, DateType"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"35bdeec8-83b8-4962-a7d4-9745c821d109","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#schema\n#It involves nested JSON File, So need to define Nested Elements schema separately, which will be inherted by new formed parent schema\nname_sch = StructType(fields = [ StructField(\"forename\", StringType(), True),\n                                 StructField(\"surname\", StringType(), True)   \n    \n])\nsch = StructType(fields = [StructField(\"driverId\", IntegerType(), False),\n                                    StructField(\"driverRef\", StringType(), True),\n                                   StructField(\"number\", IntegerType(), True),\n                                   StructField(\"code\", StringType(), True),\n                                   StructField(\"name\", name_sch, True),\n                                   StructField(\"dob\", DateType(), True),\n                                   StructField(\"nationality\", StringType(), True) ,\n                                   StructField(\"url\", StringType(), True) \n    \n])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f2eb79a8-f129-4c82-8d1d-fa21563179e2","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["output = filename(\"2021-03-21\")\ndf = spark.read.schema(sch).json(f\"{raw_path}/{output}/drivers.json\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a36b3ae5-a6e9-48cc-8b4c-4744ed41a3a1","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### Transformations (Columns)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b8046265-f7f8-47ff-ba05-19da9e9f92b2","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.sql.functions import current_timestamp, lit, col, concat"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0d5aa7c1-007d-45bf-ac6e-e0126997e187","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["final_df = df.withColumn(\"name\", concat(col(\"name.forename\"), lit(\" \"), col(\"name.surname\"))) \\\n.withColumn(\"ingestion_date\", current_timestamp()) \\\n.withColumnRenamed(\"driverId\", \"driver_id\") \\\n.withColumnRenamed(\"driverRef\", \"driver_ref\") \\\n.drop(\"url\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"70d93983-9dfc-4896-9dc0-d29904fe7f49","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### Writing to Spark Tables As Parquet format"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"71c8a0bc-4bc3-4024-be2a-745dff9d9e3d","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["final_df.write.mode(\"overwrite\").format(\"parquet\").saveAsTable(\"f1_processed.drivers\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f7a0b215-7669-442d-90cc-f9da901bf340","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4f9aecfd-6e54-4bc3-a749-9f284aea4281","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"drivers","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{"input":{"nuid":"60dafa4b-dee0-450b-9c26-56a6b22ff231","currentValue":"2021-03-21","widgetInfo":{"widgetType":"text","name":"input","defaultValue":"2021-03-21","label":null,"options":{"widgetType":"text","validationRegex":null}}}},"notebookOrigID":474225035777130}},"nbformat":4,"nbformat_minor":0}
